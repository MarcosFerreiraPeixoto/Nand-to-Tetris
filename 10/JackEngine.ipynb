{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, re\n",
    "\n",
    "class JackTokenizer:\n",
    "    def __init__(self, file):\n",
    "        with open(file) as f:\n",
    "            '''Opens the input .jack file and gets ready to tokenize it.'''\n",
    "            self.code = f.readlines()\n",
    "            self.code = self.removeWhiteSpace(self.code)\n",
    "            \n",
    "            self.tokens = self.getTokens(self.code)\n",
    "            self.counter = 0\n",
    "            self.current_token = ''         \n",
    "\n",
    "    def hasMoreTokens (self):\n",
    "        '''Are there more commands in the input file?'''\n",
    "        \n",
    "        if self.counter < len(self.tokens):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def advance (self):\n",
    "        '''Reads the next token and makes it the current \n",
    "        token. Should be called only if hasMoreCommands()\n",
    "        is true. Initially there is no current command.'''\n",
    "\n",
    "        \n",
    "        self.current_token = self.tokens[self.counter]\n",
    "        self.counter += 1\n",
    "    \n",
    "    def tokenType (self):\n",
    "        '''Returns the type of the current token, as a\n",
    "        constant.'''\n",
    "        \n",
    "        key_words = ['class', 'constructor', 'function', 'method', 'field', 'static', 'var', 'int', 'char', 'boolean', 'void', 'true', 'false', 'null', 'this', 'let', 'do', 'if', 'else', 'while', 'return']\n",
    "        symbols = ['{', '}', '(', ')', '[', ']', '.', ',', ';', '+', '-', '*', '/', '&', '|', '<', '>', '=', '~']\n",
    "   \n",
    "        if self.current_token in key_words:\n",
    "            return 'KEYWORD'\n",
    "        elif self.current_token in symbols:\n",
    "            return 'SYMBOL'\n",
    "        elif self.current_token.isnumeric():\n",
    "            return 'INT_CONST'\n",
    "        elif self.current_token[0] == '\"':\n",
    "            return 'STRING_CONST'\n",
    "        else:\n",
    "            return 'IDENTIFIER'\n",
    "\n",
    "    def keyWord (self):\n",
    "        return self.current_token.upper()\n",
    "    \n",
    "    def symbol (self):\n",
    "        return self.current_token\n",
    "    \n",
    "    def identifier (self):\n",
    "        return self.current_token\n",
    "    \n",
    "    def intVal (self):\n",
    "        return int(self.current_token)\n",
    "    \n",
    "    def stringVal (self):\n",
    "        return self.current_token.replace('\"','')\n",
    "\n",
    "    @staticmethod\n",
    "    def removeWhiteSpace (code):\n",
    "        \n",
    "        code_without_white_space = []\n",
    "        \n",
    "        for line in code:\n",
    "            line = line.split('\\n', 1)[0]\n",
    "            line = line.split('//', 1)[0]\n",
    "            line = line.split('/**',1)[0]\n",
    "            line = line.split('/*',1)[0]\n",
    "            line = line.strip()\n",
    "            code_without_white_space.append(line)\n",
    "        \n",
    "        code_without_white_space = list(filter(None, code_without_white_space))\n",
    "        \n",
    "        return code_without_white_space\n",
    "\n",
    "    @staticmethod\n",
    "    def getTokens (code_without_white_space):\n",
    "        token_list = []\n",
    "\n",
    "        #Creating a list with all tokens\n",
    "        for code_line in code_without_white_space:\n",
    "            code_line = re.split('(\")', code_line) #Spliting the Strings\n",
    "            j = 0\n",
    "            while (j < len(code_line)):\n",
    "                \n",
    "                #Dealing with StringConstant Tokens\n",
    "                if code_line[j] == '\"':\n",
    "                    token_list.append('\"' + code_line[j+1] + '\"')\n",
    "                    j += 2\n",
    "                \n",
    "                #Dealing with all other tokens\n",
    "                else:\n",
    "                    tokens = re.split('(\\W)', code_line[j])\n",
    "                    for token in tokens:\n",
    "                        token_list.append(token)\n",
    "                \n",
    "                j += 1\n",
    "        \n",
    "        token_list = [token for token in token_list if (token != '' and token != ' ')]\n",
    "\n",
    "        return token_list\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main ():\n",
    "    file_dir = input('Please, insert the file name:')\n",
    "\n",
    "    if file_dir[-1] == '/': #Verifying if the input is a file or a folder\n",
    "        os.chdir(file_dir)\n",
    "        files = glob.glob(\"*.jack\")\n",
    "        dir_name = file_dir.split('/')[-2]\n",
    "        \n",
    "        #code_writer = CodeWriter(dir_name + '.asm')\n",
    "        \n",
    "        # if 'Sys.jack' in files:\n",
    "        #     code_writer.writeCall (arg1='Sys.init', arg2='0')\n",
    "\n",
    "    else:\n",
    "        files = [file_dir]\n",
    "        #code_writer = CodeWriter(files[0] + '.asm')\n",
    "\n",
    "    \n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        arg1 = ''\n",
    "        arg2 = ''\n",
    "\n",
    "        tokenizer = JackTokenizer(file)\n",
    "\n",
    "        while (tokenizer.hasMoreTokens() == True):\n",
    "            tokenizer.advance()\n",
    "            token_type = tokenizer.tokenType()\n",
    "            \n",
    "            if token_type == 'KEYWORD':  \n",
    "                key_word = tokenizer.keyWord()\n",
    "                #code_writer.writePushPop(token_type, arg1, arg2, file)\n",
    "\n",
    "            elif token_type == 'SYMBOL':\n",
    "                symbol = tokenizer.symbol()\n",
    "                #code_writer.writeArithmetic(arg1)\n",
    "\n",
    "            elif token_type == 'IDENTIFIER':\n",
    "                identifier = tokenizer.identifier()\n",
    "                #code_writer.writeLabel(arg1)\n",
    "\n",
    "            elif token_type == 'INT_VAL':\n",
    "                int_val = tokenizer.intVal()\n",
    "                #code_writer.writeGoto(arg1)\n",
    "\n",
    "            elif token_type == 'STRING_VAL':\n",
    "                string_val = tokenizer.stringVal()\n",
    "                #code_writer.writeIf(arg1)\n",
    "\n",
    "    #code_writer.Close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adc1fd1a4b8c764c52852e42b10ea6aaf40f3ebe47b5be7cd49ce1732141673f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
